<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://fawolfmann.github.io/aboutme/feed.xml" rel="self" type="application/atom+xml" /><link href="https://fawolfmann.github.io/aboutme/" rel="alternate" type="text/html" /><updated>2020-07-06T21:17:21-05:00</updated><id>https://fawolfmann.github.io/aboutme/feed.xml</id><title type="html">Fabian Wolfmann</title><subtitle>My experiences</subtitle><entry><title type="html">Image classification of wheat plant disease</title><link href="https://fawolfmann.github.io/aboutme/2019/12/01/Image-Clasification.html" rel="alternate" type="text/html" title="Image classification of wheat plant disease" /><published>2019-12-01T00:00:00-06:00</published><updated>2019-12-01T00:00:00-06:00</updated><id>https://fawolfmann.github.io/aboutme/2019/12/01/Image-Clasification</id><content type="html" xml:base="https://fawolfmann.github.io/aboutme/2019/12/01/Image-Clasification.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2019-12-01-Image Clasification.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This was my final project to achieve the title of compute engineer. 
In this blog i'll explain how i did it and which tools i used.&lt;/p&gt;
&lt;p&gt;In this project i created my own image dataset to work with.
Some of the code used is on &lt;a href=&quot;https://github.com/fawolfmann/Tesis&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This project was created with the help of &lt;a href=&quot;https://www.argentina.gob.ar/inta&quot;&gt;INTA&lt;/a&gt; Argentinian agriculture institute and received a scholarship of &lt;a href=&quot;https://www.unc.edu.ar/ciencia-y-tecnolog%c3%ada/&quot;&gt;SECyT&lt;/a&gt; Argentinian University Technology and Science secretary.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;The-problem&quot;&gt;The problem&lt;a class=&quot;anchor-link&quot; href=&quot;#The-problem&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The problem we pose is the lose of grain on wheat harvest caused by leaf disease.&lt;/p&gt;
&lt;p&gt;In the next images we see the kind of leaf disease that are more common in the wheat.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Healthy&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Mildew&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Leaf Spot&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Rust&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://fawolfmann.github.io/aboutme/images/tesis/problem1.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://fawolfmann.github.io/aboutme/images/tesis/problem2.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://fawolfmann.github.io/aboutme/images/tesis/problem3.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;&lt;img src=&quot;https://fawolfmann.github.io/aboutme/images/tesis/problem4.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As you can see in the images they are slightly different, with the idea is to classify this images and define if a leaf have a disease.&lt;/p&gt;
&lt;p&gt;So now we have defined our problem next we will see wich technic we used.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Convolutions-neural-networks&quot;&gt;Convolutions neural networks&lt;a class=&quot;anchor-link&quot; href=&quot;#Convolutions-neural-networks&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;For the image classification we will use CNN or Convolutions neural networks. 
This is not a CNN course but will make a little intro.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;CNN-Architecture&quot;&gt;CNN Architecture&lt;a class=&quot;anchor-link&quot; href=&quot;#CNN-Architecture&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;https://fawolfmann.github.io/aboutme/images/tesis/cnn_architecture.png&quot; alt=&quot;&quot; /&gt;
Image from &lt;a href=&quot;https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks&quot;&gt;Google&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A CNN basically is made of 2 modules, the first is the convolutional module that is used to create a feature map of an image. It made convolution with the patterns it was trained, in the firsts layers it look for basics patters ass lines or circles but in the deep convolutions it look for more complex patterns as a leg or a face in the case of a CNN trained to classify people.&lt;/p&gt;
&lt;p&gt;The second module is the classification module, its a dense layer or fully connected layer that use the feature map as input and give a classification as an output, it trains the connection weights to classify.&lt;/p&gt;
&lt;p&gt;This is a very short intro if you want to get a deeper knowleadge of computer vision i recomnend this &lt;a href=&quot;http://cs231n.stanford.edu/&quot;&gt;Standford Course&lt;/a&gt; contains the slides and syllabus and the YouTube &lt;a href=&quot;https://www.youtube.com/watch?v=vT1JzLTH4G4&quot;&gt;videos&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Creation-of-dataset&quot;&gt;Creation of dataset&lt;a class=&quot;anchor-link&quot; href=&quot;#Creation-of-dataset&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We create an image dataset crawling image from the web and taking photos in the field. After the images where validated and labeled we got:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Label&lt;/th&gt;
&lt;th style=&quot;text-align:center&quot;&gt;Amount&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Healthy&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;113&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Mildew&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;102&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Leaf Spot&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;122&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center&quot;&gt;Rust&lt;/td&gt;
&lt;td style=&quot;text-align:center&quot;&gt;159&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This is a small amount of pictures to work with but we handle to generate a good solution&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Installation&quot;&gt;Installation&lt;a class=&quot;anchor-link&quot; href=&quot;#Installation&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;To the training part I install everything on a server with a Titan X GPU&lt;/p&gt;
&lt;p&gt;I used docker with a Tensorflow 2.0 image and run everything on Jupyters notebooks. All the code was build with Keras.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Training-of-models&quot;&gt;Training of models&lt;a class=&quot;anchor-link&quot; href=&quot;#Training-of-models&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In the training steps I made 3 iteration to get the final results.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Iteration-1&quot;&gt;Iteration 1&lt;a class=&quot;anchor-link&quot; href=&quot;#Iteration-1&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;First I used my dataset on transfer learning with several pretrained models, trained with Imagenet, this is easly doit with:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;applications&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xception&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Xception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                                                   &lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMG_SHAPE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                   &lt;span class=&quot;n&quot;&gt;include_top&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                   &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;imagenet&amp;#39;&lt;/span&gt;
                                                   &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Here you have to define the shape of the input usualy 224x224 or 512x512, and define if you want to get the top layer, the clasification module, with all the Imagenet classes.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;In this iteration we also used &lt;a href=&quot;https://bair.berkeley.edu/blog/2019/06/07/data_aug/&quot;&gt;Data augmentation&lt;/a&gt;, keras give you a good tool to work with this&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_generator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preprocessing&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ImageDataGenerator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rescale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                                  &lt;span class=&quot;n&quot;&gt;validation_split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;                            
                                                                  &lt;span class=&quot;n&quot;&gt;zoom_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                                  &lt;span class=&quot;n&quot;&gt;horizontal_flip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                                  &lt;span class=&quot;n&quot;&gt;rotation_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;
                                                                 &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Here you define the way that keras will augment your images, all the configuration can be fund &lt;a href=&quot;https://keras.io/api/preprocessing/image/&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;But this iteration wasn't succesfull, the maximum accuracy achived was &lt;strong&gt;65.8%&lt;/strong&gt; on the validation dataset, not even the test dataset. 
So i keep training with diferent ways.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Iteration-2&quot;&gt;Iteration 2&lt;a class=&quot;anchor-link&quot; href=&quot;#Iteration-2&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;So then i think why my model went wrong, and talking with some professor of my university the y told me to look for a base dataset to make the all the full training and i found &lt;a href=&quot;https://www.kaggle.com/emmarex/plantdisease&quot;&gt;PlantVillage&lt;/a&gt; a very similar dataset, it contains 50.000+ images of plant leaf with and without diseases.&lt;/p&gt;
&lt;p&gt;After making the full training with this new dataset, I made the transfer learning with my own dataset.&lt;/p&gt;
&lt;p&gt;Unfortunatly i didnt get so much better results.  With a maximum of &lt;strong&gt;72.3%&lt;/strong&gt; of accuracy on validation dataset.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Android-app-implementation&quot;&gt;Android app implementation&lt;a class=&quot;anchor-link&quot; href=&quot;#Android-app-implementation&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;After we trained successfully a model we convert it with TensorflowLite and created an Android app to use this trained model and make predictions on the device.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Conclusions&quot;&gt;Conclusions&lt;a class=&quot;anchor-link&quot; href=&quot;#Conclusions&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;At the end of this work i realased that the most time cosuming task was to manipulate the data to make it work with your model.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry></feed>